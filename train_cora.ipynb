{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "static-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN related libraries\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "from torch.optim import Adam\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import sys \n",
    "sys.path.append('./')\n",
    "\n",
    "# from the code \n",
    "from model.GAT import GAT\n",
    "from utils.layers import GAT_layer\n",
    "\n",
    "# data related \n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ranking-punishment",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Cora():\n",
      "======================\n",
      "Number of graphs: 1\n",
      "Number of features: 1433\n",
      "Number of classes: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = Planetoid(root='/tmp/Cora', name='Cora',transform=T.NormalizeFeatures())\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('======================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "beautiful-vatican",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index=dataset[0].edge_index\n",
    "nodes_features=dataset[0].x\n",
    "nodes_labels=dataset[0].y\n",
    "\n",
    "#parameters_GAT_network={'num_features_per_layer'={}}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3fdab0",
   "metadata": {},
   "source": [
    "### Bellow we just test the GAT_layer to check that is returning what we expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9b734c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_test=GAT_layer(nodes_features.shape[0],nodes_features.shape[1],8,8,nn.ELU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "opened-mixer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1441,  0.0197, -0.0162,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0667,  0.1129, -0.0322,  ...,  0.0610,  0.0526, -0.0135],\n",
       "         [ 0.0410,  0.0206, -0.0472,  ...,  0.0064, -0.0332, -0.0613],\n",
       "         ...,\n",
       "         [-0.0078,  0.1516, -0.0268,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.5963,  0.0873, -0.3285,  ..., -0.0198,  0.1006, -0.1098],\n",
       "         [ 0.0622,  0.2269, -0.0720,  ..., -0.0416,  0.0839,  0.1467]],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],\n",
       "         [ 633, 1862, 2582,  ...,  598, 1473, 2706]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_test((nodes_features,edge_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f04cdd3",
   "metadata": {},
   "source": [
    "### Bellow we test the GAT network. We put two layers, similar to the model used in the experiment in the original paper, which is the one we'll use latter for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75a47fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test=GAT(2,nodes_features.shape[0],[nodes_features.shape[1],8,7],[8,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90c59562",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_features=model_test((nodes_features,edge_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79f7b9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1758, 0.2000, 0.1018, 0.1263, 0.1113, 0.1947, 0.0901],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_features[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f65036f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9661, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's check that the output has the right shape to pass to the loss function\n",
    "loss=nn.CrossEntropyLoss()\n",
    "loss(out_features[0],nodes_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ea7a1a",
   "metadata": {},
   "source": [
    "## Training the network in the cora dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9856ba",
   "metadata": {},
   "source": [
    "### First we define the hyperparameters of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146396d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "C=7 # number of classes of the cora dataset\n",
    "params_network={'num_layers':2,\n",
    "               'num_nodes':nodes_features.shape[0],\n",
    "                'num_features_per_layer':[nodes_features.shape[1],8,C],\n",
    "                'num_heads_per_layer':[8,1],\n",
    "                 'num_epochs':500\n",
    "               }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97ff5f1",
   "metadata": {},
   "source": [
    "### Divide the dataset in training, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b440cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset starts in node 0 and comprises 140 nodes\n",
      "The validation dataset starts in node 1708 and comprises 1000 nodes\n",
      "The test dataset starts in node 140 and comprises 500 nodes\n"
     ]
    }
   ],
   "source": [
    "# indices of each set according to the masks given in the dataset (i.e we use the same assignation as in the original paper)\n",
    "training_set_indices=(dataset[0].train_mask).nonzero(as_tuple=False).flatten()\n",
    "test_set_indices=(dataset[0].test_mask).nonzero(as_tuple=False).flatten()\n",
    "val_set_indices=(dataset[0].val_mask).nonzero(as_tuple=False).flatten()\n",
    "print('The training dataset starts in node {:} and comprises {:} nodes'.format(training_set_indices[0].numpy(),training_set_indices.shape[0]))\n",
    "print('The validation dataset starts in node {:} and comprises {:} nodes'.format(test_set_indices[0].numpy(),test_set_indices.shape[0]))\n",
    "print('The test dataset starts in node {:} and comprises {:} nodes'.format(val_set_indices[0].numpy(),val_set_indices.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27a9beae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the labels for the training set\n",
    "nodes_labels_training_set=nodes_labels.index_select(0,training_set_indices)\n",
    "#validation\n",
    "nodes_labels_validation_set=nodes_labels.index_select(0,val_set_indices)\n",
    "#test\n",
    "nodes_labels_test_set=nodes_labels.index_select(0,test_set_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a440ede0",
   "metadata": {},
   "source": [
    "Now we have everything we need in order to start the training process. Let's define the model and run the learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "34d41ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=GAT(params_network['num_layers'],params_network['num_nodes'],params_network['num_features_per_layer'],params_network['num_heads_per_layer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a9c92d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's run the training loop \n",
    "def train_gat(params_network,num_epochs=10000,val_lapse=1000,perform_test='True'):\n",
    "    #device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    device=torch.device('mps')\n",
    "    time_start=time.time()\n",
    "    model_gat=GAT(params_network['num_layers'],params_network['num_nodes'],params_network['num_features_per_layer'],params_network['num_heads_per_layer']).to(device)\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = Adam(model_gat.parameters(), lr=0.01,weight_decay=0.0005) # weight decay corresponds to the L2 penalty, which in the original implementation is chosen to the value we put here\n",
    "    \n",
    "    nodes_features_dev=nodes_features.to(device)\n",
    "    edge_index_dev=edge_index.to(device)\n",
    "    graph_data=(nodes_features_dev,edge_index_dev)\n",
    "    \n",
    "    nodes_labels_training_set_dev=nodes_labels_training_set.to(device)\n",
    "    nodes_labels_validation_set_dev=nodes_labels_validation_set.to(device)\n",
    "    nodes_labels_test_set_dev=nodes_labels_test_set.to(device)\n",
    "    \n",
    "    training_set_indices_dev=training_set_indices.to(device)\n",
    "    test_set_indices_dev=test_set_indices.to(device)\n",
    "    val_set_indices_dev=val_set_indices.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(epoch)\n",
    "        \n",
    "        model_gat.train() #set model in training mode\n",
    "        \n",
    "        print(next(model_gat.parameters()).device)\n",
    "        # We do a forward pass of the model and extract the unnormalized logits for the training set \n",
    "        # shape = (N, C) where N is the number of nodes in the split (train/val/test) and C is the number of classes\n",
    "        nodes_unnormalized_out_train = model_gat(graph_data)[0].index_select(0,training_set_indices_dev)\n",
    "        \n",
    "        print(nodes_unnormalized_out_train.device)\n",
    "        loss=loss_fn(nodes_unnormalized_out_train,nodes_labels_training_set_dev)\n",
    "        \n",
    "        #Optimizer backward evaluation\n",
    "        \n",
    "        optimizer.zero_grad()  \n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "        \n",
    "        # Compute the accuracy\n",
    "\n",
    "        # Finds the index of maximum (unnormalized) score for every node and that's the class prediction for that node.\n",
    "        # Compare those to true (ground truth) labels and find the fraction of correct predictions -> accuracy metric.\n",
    "        predictions = torch.argmax(nodes_unnormalized_out_train, dim=-1)\n",
    "        accuracy = torch.sum(torch.eq(predictions, nodes_labels_training_set_dev).long()).item() / len(nodes_labels_training_set_dev)\n",
    "        \n",
    "        #TensorBoard summary writter \n",
    "        writer=SummaryWriter()\n",
    "        \n",
    "        writer.add_scalar('Loss/train',loss.item(),epoch)\n",
    "        writer.add_scalar('Accuracy/train',accuracy,epoch)\n",
    "        \n",
    "        print(f'time elapsed={(time.time()-time_start):.2f} [s]')\n",
    "        print(f'accuracy test={accuracy:.3f}')\n",
    "        if (epoch+1)%val_lapse==0:\n",
    "            with torch.no_grad():\n",
    "                nodes_unnormalized_out_val = model_gat(graph_data)[0].index_select(0,val_set_indices_dev)\n",
    "                loss_val=loss_fn(nodes_unnormalized_out_val,nodes_labels_validation_set_dev)\n",
    "                predictions = torch.argmax(nodes_unnormalized_out_val, dim=-1)\n",
    "                accuracy = torch.sum(torch.eq(predictions, nodes_labels_validation_set_dev).long()).item() / len(nodes_labels_validation_set_dev)\n",
    "        \n",
    "                \n",
    "                writer.add_scalar('Loss/validation',loss_val.item(),epoch)\n",
    "                writer.add_scalar('Accuracy/validation',accuracy,epoch)\n",
    "                print(f'GAT training: time elapsed= {(time.time() - time_start):.2f} [s] | epoch={epoch + 1} | val acc={accuracy}')\n",
    "        \n",
    "    if perform_test:\n",
    "        with torch.no_grad():\n",
    "            nodes_unnormalized_out_test = model_gat(graph_data)[0].index_select(0,test_set_indices_dev)\n",
    "            loss_test=loss_fn(nodes_unnormalized_out_test,nodes_labels_test_set_dev)\n",
    "            predictions = torch.argmax(nodes_unnormalized_out_test, dim=-1)\n",
    "            accuracy = torch.sum(torch.eq(predictions, nodes_labels_test_set_dev).long()).item() / len(nodes_labels_test_set_dev)\n",
    "        print(f'Test accuracy = {test_acc}')\n",
    "    torch.save({'state_dict':model.state_dict},os.path.join(os.path.dirname('model'), 'model','saved_model','model_gat_trained.pt'))\n",
    "    writer.close()\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "30a7fc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "mps:0\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/lopetegui/Documents/ENS/3eme_annee/Deep_learning/project/GAT_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3442, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/qn/dr9486bd45j0q2rhfjp74khc0000gn/T/ipykernel_1606/1029926391.py\", line 1, in <module>\n",
      "    train_gat(params_network,num_epochs=1001)\n",
      "  File \"/var/folders/qn/dr9486bd45j0q2rhfjp74khc0000gn/T/ipykernel_1606/66144564.py\", line 31, in train_gat\n",
      "    nodes_unnormalized_out_train = model_gat(graph_data)[0].index_select(0,training_set_indices_dev)\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lopetegui/Documents/ENS/3eme_annee/Deep_learning/project/GAT_env/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lopetegui/Documents/ENS/3eme_annee/Deep_learning/project/repo/GAT-DL-DIY/model/GAT.py\", line 36, in forward\n",
      "    return self.gat_network(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lopetegui/Documents/ENS/3eme_annee/Deep_learning/project/GAT_env/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lopetegui/Documents/ENS/3eme_annee/Deep_learning/project/GAT_env/lib/python3.11/site-packages/torch/nn/modules/container.py\", line 204, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"/Users/lopetegui/Documents/ENS/3eme_annee/Deep_learning/project/GAT_env/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lopetegui/Documents/ENS/3eme_annee/Deep_learning/project/repo/GAT-DL-DIY/utils/layers.py\", line 102, in forward\n",
      "    h_new=self.get_weighted_contirbutions_new_features(h_proj_lift,att_weights_per_edge_soft_maxed,edge_index)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lopetegui/Documents/ENS/3eme_annee/Deep_learning/project/repo/GAT-DL-DIY/utils/layers.py\", line -1, in get_weighted_contirbutions_new_features\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lopetegui/Documents/ENS/3eme_annee/Deep_learning/project/GAT_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2057, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lopetegui/Documents/ENS/3eme_annee/Deep_learning/project/GAT_env/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lopetegui/Documents/ENS/3eme_annee/Deep_learning/project/GAT_env/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lopetegui/Documents/ENS/3eme_annee/Deep_learning/project/GAT_env/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lopetegui/Documents/ENS/3eme_annee/Deep_learning/project/GAT_env/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lopetegui/Documents/ENS/3eme_annee/Deep_learning/project/GAT_env/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "                                              ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lopetegui/Documents/ENS/3eme_annee/Deep_learning/project/GAT_env/lib/python3.11/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/lopetegui/Documents/ENS/3eme_annee/Deep_learning/project/GAT_env/lib/python3.11/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lopetegui/Documents/ENS/3eme_annee/Deep_learning/project/GAT_env/lib/python3.11/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/lopetegui/Documents/ENS/3eme_annee/Deep_learning/project/GAT_env/lib/python3.11/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lopetegui/Documents/ENS/3eme_annee/Deep_learning/project/GAT_env/lib/python3.11/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/lopetegui/Documents/ENS/3eme_annee/Deep_learning/project/GAT_env/lib/python3.11/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"/Users/lopetegui/Documents/ENS/3eme_annee/Deep_learning/project/GAT_env/lib/python3.11/site-packages/executing/executing.py\", line 190, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "train_gat(params_network,num_epochs=1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "633ce58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GAT(\n",
       "  (activation): Softmax(dim=-1)\n",
       "  (gat_network): Sequential(\n",
       "    (0): GAT_layer(\n",
       "      (linear): Linear(in_features=1433, out_features=64, bias=True)\n",
       "      (leakyReLu): LeakyReLU(negative_slope=0.2)\n",
       "      (softmax): Softmax(dim=-1)\n",
       "      (dropout): Dropout(p=0.6, inplace=False)\n",
       "      (activation): ELU(alpha=1.0)\n",
       "    )\n",
       "    (1): GAT_layer(\n",
       "      (linear): Linear(in_features=64, out_features=7, bias=True)\n",
       "      (leakyReLu): LeakyReLU(negative_slope=0.2)\n",
       "      (softmax): Softmax(dim=-1)\n",
       "      (dropout): Dropout(p=0.6, inplace=False)\n",
       "      (activation): Softmax(dim=-1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(torch.device('mps'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "82339e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deb4235",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
